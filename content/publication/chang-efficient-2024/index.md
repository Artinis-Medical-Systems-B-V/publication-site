---
abstract: Oxygen saturation is a critical parameter widely used in clinical practice
  to assess the concentration of oxygen in the blood. Recently, hyperspectral imaging-based
  oximetry techniques have been proposed for broad applications of two-dimensional
  information without sensor contact. However, these methods suffer from high computational
  complexity and inefficiency due to the large size of hyperspectral data cubes. In
  this study, we investigate an efficient tissue oxygen saturation (StO2) mapping
  from hyperspectral image using a generative adversarial network (GAN). The model
  was trained on hyperspectral images acquired from 40 healthy individuals. To reduce
  computational load while maintaining performance, the Non-dominated Sorting Genetic
  Algorithm II (NSGA-II) was then employed to identify the optimal combination of
  hyperspectral bands. The selected optimal band combinations included both visible
  and near-infrared (NIR) bands. The GAN-based model with the ten-band combination
  estimated StO2 effectively, achieving a root mean squared error (RMSE) of 0.1169
  ± 0.0350 . The trained model was then applied to palm and sole images of 20 patients
  with type 2 diabetes mellitus (DM) to validate its performance. The performance
  on patient data was comparable to that obtained from healthy individuals, with the
  best results achieved using the ten-band combination (RMSE =0.1077 ± 0.0341 ). In
  conclusion, the developed efficient hyperspectral image-based oxygenation mapping
  method demonstrated robust performance for patients with type 2 DM as well as healthy
  subjects.
authors:
- Minhye Chang
- Wonju Lee
- Kye Young Jeong
- Jun Wan Kim
- Chang Hee Jung
categories:
- PortaLite
date: '2024-10-30'
doi: 10.1109/ACCESS.2024.3482280
featured: false
projects: []
publication: '*IEEE Access*'
publication_types:
- '2'
publishDate: 2024-10-30 08:43:39.356558+00:00
tags: []
title: Efficient Mapping of Tissue Oxygen Saturation Using Hyperspectral Imaging and
  GAN

---
