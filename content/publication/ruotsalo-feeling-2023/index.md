---
abstract: The present notion of visual similarity is based on features derived from
  image contents. This ignores the users' emotional or affective experiences toward
  the content, and how users feel when they search for images. Here we consider valence,
  a positive or negative quantification of affective appraisal, as a novel dimension
  of image similarity. We report the largest neuroimaging experiment that quantifies
  and predicts the valence of visual content by using functional near-infrared spectroscopy
  from brain-computer interfacing. We show that affective similarity can be (1)~decoded
  directly from brain signals in response to visual stimuli, (2)~utilized for predicting
  affective image similarity with an average accuracy of 0.58 and an accuracy of 0.65
  for high-arousal stimuli, and (3)~effectively used to complement affective similarity
  estimates of content-based models; for example when fused fNIRS and image rankings
  the retrieval F-measure@20 is 0.70. Our work opens new research avenues for affective
  multimedia analysis, retrieval, and user modeling.
authors:
- Tuukka Ruotsalo
- Kalle Mäkelä
- Michiel M. Spapé
- Luis A. Leiva
categories:
- Brite
date: '2023-11-09'
doi: 10.1145/3581783.3613442
featured: false
projects:
- brain-computer-interfaces
- brain-fnirs-prefrontal-cortex
publication: '*Proceedings of the 31st ACM International Conference on Multimedia*'
publication_types:
- '1'
publishDate: 2023-11-09 14:44:01.706729+00:00
tags: []
title: Feeling Positive? Predicting Emotional Image Similarity from Brain Signals

---
